{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/apd1995/AMP_matrix_recovery/blob/apd1995-blocksoft-approx-jacobian-poisson-jit-3/updating_params.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHzGltMdJC9T",
    "outputId": "d703f29f-2aea-45d8-ce68-647b1dcf1c72"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92r1HoMqKeDu"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from google.cloud import bigquery\n",
    "import multiprocessing as mp\n",
    "from google.colab import auth\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rE7dxKiny0b"
   },
   "source": [
    "auth.authenticate_user()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7_BFwwSKhLD",
    "outputId": "79de9426-5302-4ffb-e57c-d02fea360c4a"
   },
   "source": [
    "default_directory = 'Andrew+Apratim+Dave/experimental_design'\n",
    "import sys\n",
    "use_default_directory = input(\"Please enter Y if your directory is Andrew+Apratim+Dave/experimental_design.\\nPlease enter N if not. \")\n",
    "if use_default_directory == 'Y':\n",
    "  import_directory = default_directory\n",
    "elif use_default_directory == 'N':\n",
    "  import_directory = input(\"Please enter your working directory in Google Drive. \\nFor example, when you go to Google Drive, if your module is located in Folder1 -> Folder2, please write Folder1/Folder2. \")\n",
    "sys.path.append('/content/drive/MyDrive/'+str(import_directory))\n",
    "from experimental_design import logreg_data, kalish_optimal_two_point_logistic, white_optimal_two_point_logistic\n",
    "%load_ext google.colab.data_table"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbIvBOrUKtBE"
   },
   "source": [
    "def get_df_from_project(project_id, table_name):\n",
    "\n",
    "  client = bigquery.Client(project=project_id)\n",
    "\n",
    "  query = f\"SELECT * FROM `{table_name}`\"\n",
    "\n",
    "  df = client.query(query).to_dataframe()\n",
    "\n",
    "  return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hnJixDqoK5LF",
    "outputId": "f1cfd744-4da2-492d-8d48-d55d9b62924b"
   },
   "source": [
    "# df_integer_scale = get_df_from_project('hs-deep-lab-donoho', 'EMS.comr-N50-larger-grids')\n",
    "# df_integer_scale\n",
    "\n",
    "# df_AMP_coarse = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_blocksoft_02_1')\n",
    "# df_AMP_coarse\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_blocksoft_10_normal')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_JS_1_normal')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_normal_bayes_2_1')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_normal_bayes_approx_jacobian')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_JS_approx_jacobian_cov')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_JS_normal_cov_regenerated')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_JS_normal_regenerated_se')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_JS_approx_jacobian_normal_jit_3')\n",
    "# df_AMP\n",
    "\n",
    "# df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_JS_approx_jacobian_poisson_jit')\n",
    "# df_AMP\n",
    "\n",
    "df_AMP = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_blocksoft_approx_jacobian_poisson_jit')\n",
    "df_AMP"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJW3Xv6ZmqO9",
    "outputId": "4eeccc35-1dcb-4011-de44-66992810c6a5"
   },
   "source": [
    "np.mean(df_AMP['time_seconds']/df_AMP['iter_count'])\n",
    "# max(df_AMP['time_seconds'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "tzIyavJIn2Ac",
    "outputId": "06342238-3be0-4b66-fef7-b4ca25fb6605"
   },
   "source": [
    "df = df_AMP[df_AMP['signal_nrow']>=400]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['time_seconds'], bins = 30)\n",
    "df.shape[0], np.median(df['time_seconds']), np.mean(df['time_seconds']), np.mean(df['time_seconds']>500)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkTHagNWR9S0"
   },
   "source": [
    "Use the following function to use subsets of the full dataset, which is much easier to handle considering memory limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JHPBJlttXhl"
   },
   "source": [
    "def subset_df_from_project(project_id, table_name, signal_nrow):\n",
    "  client = bigquery.Client(project=project_id)\n",
    "\n",
    "  query = f\"SELECT * FROM `{table_name}` WHERE signal_nrow = {signal_nrow}\"\n",
    "\n",
    "  df = client.query(query).to_dataframe()\n",
    "\n",
    "  return df\n",
    "\n",
    "# AMP_course_20 = subset_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_blocksoft_02', 20)\n",
    "# AMP_course_20\n",
    "\n",
    "AMP_course_small = subset_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_normal_bayes_2_1', 5)\n",
    "AMP_course_small.to_csv(\"temp.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg-_LoK0RLWC"
   },
   "source": [
    "df_integer_scale = get_df_from_project('hs-deep-lab-donoho', 'EMS.comr-N50-larger-grids')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MX1K8He1KwbY",
    "outputId": "c65c68c2-062f-45a5-d8db-3da8d31b2810"
   },
   "source": [
    "def save_df_in_drive(output_df):\n",
    "\n",
    "  output_name = input(\"Please write the name with which you'd like to store the output. \")\n",
    "  default_directory = 'Andrew+Apratim+Dave/experimental_design'\n",
    "  user_decision = input(\"Do you want to save your output in the default directory, that is, Andrew+Apratim+Dave/experimental_design? \\nWrite Y for yes and N for no. \")\n",
    "\n",
    "  if user_decision == \"Y\":\n",
    "    output_df.to_csv(\"/content/drive/MyDrive/\"+str(default_directory)+\"/\"+str(output_name))\n",
    "    return\n",
    "  elif user_decision == \"N\":\n",
    "    output_directory = input(\"Please write the location you want your output file to be in, in Google Drive. \\nIf it's Folder1 -> Folder2, write Folder1/Folder2 \")\n",
    "    output_df.to_csv(\"/content/drive/MyDrive/\"+str(output_directory)+\"/\"+str(output_name))\n",
    "    return\n",
    "  else:\n",
    "    print(\"Invalid choice. Please enter only Y or N. \")\n",
    "    return\n",
    "\n",
    "# save_df_in_drive(AMP_course_20)\n",
    "save_df_in_drive(df_AMP)\n",
    "# del df_integer_scale\n",
    "# save_df_in_drive(df_integer_scale)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JT-RWP2WLGAC"
   },
   "source": [
    "%load_ext rpy2.ipython"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTysIoQlSaGA"
   },
   "source": [
    "We need the bigrquery function to read gbq database. Upload the json file containing the key to session storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "an3yjrokSSps"
   },
   "source": [
    "%%R\n",
    "# install.packages(\"bigrquery\")\n",
    "library(bigrquery)\n",
    "Sys.setenv(GOOGLE_APPLICATION_CREDENTIALS = \"key_file.json\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOZD7YALWkML"
   },
   "source": [
    "%%R\n",
    "project_id <- \"hs-deep-lab-donoho\"\n",
    "sql_query <- \"SELECT signal_nrow, signal_ncol FROM EMS.comr-N50-larger-grid\"\n",
    "\n",
    "result <- query_exec(sql_query, project = project_id, billing = project_id)\n",
    "\n",
    "data_frame <- as.data.frame(result)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gln5AlHWWwEJ",
    "outputId": "0dba8338-ecc6-474b-b8b3-69ede0569a92"
   },
   "source": [
    "%%R\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(ggplot2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgvREDwuLap6",
    "outputId": "726737c2-bfaa-4f66-a997-5fabfbc49514"
   },
   "source": [
    "%%R\n",
    "#filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/raw_data_combined.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/raw_data_integer_scale_full.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/raw_data_AMP_blocksoft.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_course_20.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/raw_data_AMP_blocksoft_corrected.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/raw_data_AMP_blocksoft_larger.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/raw_data_comr.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_poisson.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_normal.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_normal_bayes.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_normal_bayes_approx_jacobian.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_normal_approx_jacobian.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_normal_approx_jac.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_normal_regenerated.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_normal_jax.csv\"\n",
    "# filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_JS_poisson_jit.csv\"\n",
    "filename = \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_blocksoft_poisson_jit.csv\"\n",
    "raw_data = read.csv(filename)\n",
    "raw_data = subset(raw_data, select = -X)\n",
    "raw_data = unique(raw_data)\n",
    "row.names(raw_data) = 1:nrow(raw_data)\n",
    "head(raw_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mc__LzUeP_NG",
    "outputId": "8a554d90-6839-4f8f-efa1-2d2c0bf3dd95"
   },
   "source": [
    "%%R\n",
    "raw_data$min_rel_err[is.na(raw_data$rel_err)] = 1\n",
    "raw_data[1,]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk5EDGIPLfng",
    "outputId": "17145ba9-18f8-4bcf-c57f-e9b9d55d1efd"
   },
   "source": [
    "%%R\n",
    "#helper functions\n",
    "deno_integrand = function(x, B, tau_sq){\n",
    "    tau = sqrt(tau_sq)\n",
    "    return((sqrt(x) - tau)*dchisq(x, B))\n",
    "}\n",
    "\n",
    "deno_integral = function(B, tau_sq){\n",
    "    return(integrate(deno_integrand, lower = tau_sq, upper = Inf, B, tau_sq)$value)\n",
    "}\n",
    "\n",
    "num_integrand = function(x, B, tau_sq){\n",
    "    tau = sqrt(tau_sq)\n",
    "    return((sqrt(x) - tau)^2*dchisq(x, B))\n",
    "}\n",
    "\n",
    "num_integral = function(B, tau_sq){\n",
    "    return(integrate(num_integrand, lower = tau_sq, upper = Inf, B, tau_sq)$value)\n",
    "}\n",
    "\n",
    "h = function(B, tau_sq){\n",
    "    return(sqrt(tau_sq)/deno_integral(B, tau_sq))\n",
    "}\n",
    "\n",
    "g = function(B, tau_sq){\n",
    "    return(sqrt(tau_sq)*num_integral(B, tau_sq)/deno_integral(B, tau_sq))\n",
    "}\n",
    "\n",
    "tau_sq_optim_eqn = function(tau_sq, sparsity, B){\n",
    "    return(h(B, tau_sq)+1-(1/sparsity))\n",
    "}\n",
    "\n",
    "#giving a huge upper bound 1e+50 instead of Inf as otherwise uniroot function breaks\n",
    "tau_sq_optim = function(sparsity, B){\n",
    "    res = uniroot(tau_sq_optim_eqn, c(0, 1e+100), sparsity, B)$root\n",
    "    return(res)\n",
    "}\n",
    "\n",
    "#main function delivering delta PT value for given sparsity and B\n",
    "predicted_delta_PT = function(sparsity, B){\n",
    "    tau_sq = tau_sq_optim(sparsity, B)\n",
    "    return((B+tau_sq+g(B, tau_sq))/(B*(1+h(B, tau_sq))))\n",
    "}\n",
    "\n",
    "predicted_delta_PT(0.25, 5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajcR5qmmLt8I"
   },
   "source": [
    "%%R\n",
    "get_LD50 = function(x, y){\n",
    "    if(sum(y) == 0){\n",
    "        return(1)\n",
    "    }\n",
    "    else if(sum(y) == length(y)){\n",
    "        return(0)\n",
    "    }\n",
    "    else{\n",
    "        logreg = glm(y~x, family = binomial(link = \"logit\"))\n",
    "        intercept = logreg$coefficients[1]\n",
    "        slope = logreg$coefficients[2]\n",
    "        LD50 = unname(-intercept/slope)\n",
    "        return(min(max(LD50, 0), 1))\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "empirical_PT_df = function(df, sparsity_lower_bound, sparsity_upper_bound){\n",
    "    dat = df %>%\n",
    "    filter(sparsity>=sparsity_lower_bound, sparsity<=sparsity_upper_bound) %>%\n",
    "    mutate(success = as.integer(rel_err < 10**2 * err_tol)) %>%\n",
    "    arrange(signal_nrow, signal_ncol, nonzero_rows, sparsity, num_measurements, undersampling_ratio, mc) %>%\n",
    "    group_by(signal_nrow, signal_ncol, nonzero_rows, sparsity) %>%\n",
    "    summarise(empirical_delta_PT = get_LD50(undersampling_ratio, success))\n",
    "\n",
    "    # dat_small = dat %>%\n",
    "    # filter(signal_nrow == min(dat$signal_nrow)) %>%\n",
    "    # mutate(pred_delta_PT = mapply(predicted_delta_PT, sparsity, signal_ncol))\n",
    "\n",
    "    # dat$pred_delta_PT = rep(dat_small$pred_delta_PT, as.integer(nrow(dat)/nrow(dat_small)))\n",
    "\n",
    "    return(dat)\n",
    "}\n",
    "\n",
    "\n",
    "# write.csv(res, \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_intger_scale.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7laqlh-FogDg",
    "outputId": "acebf604-3568-49ae-cd07-cf369aa8d617"
   },
   "source": [
    "%%R\n",
    "res_JS_normal_regenerated = empirical_PT_df(raw_data, 0, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "res_JS_normal_jax = empirical_PT_df(raw_data, 0, 1)"
   ],
   "metadata": {
    "id": "KXKHySzTqKTc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "836e7301-bccf-48b7-cfd1-8d63e0dc8c3b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "res_blocksoft_poisson_jit = empirical_PT_df(raw_data, 0, 1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TGhjio96zXi",
    "outputId": "b09f17cc-8959-40f2-d5cc-b88c7e0c12f9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "res_blocksoft_poisson_jit = res_blocksoft_poisson_jit %>%\n",
    " mutate(pred_delta_PT = predicted_delta_PT(sparsity, signal_ncol))"
   ],
   "metadata": {
    "id": "1pJdLgx7U1Hw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "write.csv(res_blocksoft_poisson_jit, \"temp.csv\")"
   ],
   "metadata": {
    "id": "gFWlV8k4VXe8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjpHi3tTsVQb",
    "outputId": "cb506892-df30-409f-d199-edb12a60f051"
   },
   "source": [
    "%%R\n",
    "df = raw_data %>% filter(signal_nrow == 800) %>% filter(sparsity == 0.3) %>% filter(selected_rows_frac == 1.0)\n",
    "df$success = as.integer(df$rel_err < 1e-3)\n",
    "success_prop = sum(df$success)/length(df$success)\n",
    "success_prop"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "# correction of intercept\n",
    "y = df$success\n",
    "x = df$undersampling_ratio\n",
    "logreg = glm(y~x, family = binomial(link = \"logit\"))\n",
    "intercept = logreg$coefficients[1]\n",
    "slope = logreg$coefficients[2]\n",
    "c(get_LD50(x, y), (-intercept + log(((1-0.495)/0.495) * (success_prop/(1-success_prop))))/slope)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVxiuoTN15VO",
    "outputId": "9749b8da-07ab-4444-c970-b05154346ec8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "g4 <- ggplot(res_blocksoft_poisson_jit, aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow))) +\n",
    "      geom_line(aes(x = sparsity, y = pred_delta_PT, color = \"predicted\"))\n",
    "      # geom_line(data = filter(res_JS_normal, signal_nrow == 800), aes(x = sparsity, y = empirical_delta_PT, color = \"actual AMP\")) +\n",
    "      # scale_color_discrete(name = \"Number of rows of signal\")\n",
    "\n",
    "g4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "SARbtR0PVJ62",
    "outputId": "3bed52d6-a57b-442a-ace9-51e3ecfcabdf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "g4 <- ggplot(res_JS_normal_jax, aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"normal\")) +\n",
    "      geom_line(data = res_JS_poisson_jit, aes(x = sparsity, y = empirical_delta_PT, color = \"poisson\"))\n",
    "      # geom_line(data = filter(res_JS_normal, signal_nrow == 800), aes(x = sparsity, y = empirical_delta_PT, color = \"actual AMP\")) +\n",
    "      # scale_color_discrete(name = \"Number of rows of signal\")\n",
    "\n",
    "g4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "RkhQMBBx69zL",
    "outputId": "e3405a97-bedb-48dc-d1bc-b8e9bc0a4154"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "g4 <- ggplot(res_JS_normal_regenerated, aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow))) +\n",
    "      geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"JS MSE curve\")) +\n",
    "      geom_line(data = res_JS_normal_jax, aes(x = sparsity, y = empirical_delta_PT, color = \"actual AMP\")) +\n",
    "      # geom_line(data = filter(res_JS_normal, signal_nrow == 800), aes(x = sparsity, y = empirical_delta_PT, color = \"actual AMP\")) +\n",
    "      scale_color_discrete(name = \"Number of rows of signal\")\n",
    "\n",
    "g4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "Haok34XkxM7c",
    "outputId": "0d8e6459-f9cd-4c87-bbb6-10d2c882287f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "dat = filter(res_JS_normal_approx_jac, sparsity >= 0.1)\n",
    "dat$sparsity = round(dat$sparsity, 2)\n",
    "alpha_grid = seq(0.001, 3, by = 0.001)\n",
    "R_grid = NULL\n",
    "for(alpha in alpha_grid){\n",
    "  reg = lm(empirical_delta_PT ~ factor(sparsity) + I(1/signal_nrow^alpha) - 1, data = dat)\n",
    "  R_grid = c(R_grid, summary(reg$r.squared))\n",
    "}\n",
    "alpha_chosen = alpha_grid[which.max(R_grid)]\n",
    "alpha_chosen = 1\n",
    "print(paste(\"chosen exponent:\", alpha_chosen))\n",
    "reg = lm(empirical_delta_PT ~ as.factor(sparsity) + I(1/signal_nrow^alpha_chosen) - 1, data = dat)\n",
    "summary(reg)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLTB45AmAZ71",
    "outputId": "f3b6980b-5a28-4751-9d79-e072209a47f4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%R\n",
    "dat2 = filter(dat, signal_nrow == 200)\n",
    "dt2 = filter(dat2, sparsity >= 0.1)\n",
    "cbind(dat2$pred_JS_PT, reg$coeff[1:(length(reg$coeff)-1)])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65cyF5x2BAzn",
    "outputId": "c7bf0add-ed3e-4888-d3be-5ef7a13e6d51"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from experimental_design import kalish_optimal_two_point_logistic, white_optimal_two_point_logistic\n",
    "df_small = df_AMP[df_AMP['selected_rows_frac'] == 0.3]\n",
    "df_small['success'] = df_small['rel_err']<100*df_small['err_tol']"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HwjK463lM0l",
    "outputId": "4976004e-4c7f-4bdc-e78b-45a8f11056a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = df_small['undersampling_ratio']\n",
    "y = df_small['success']\n",
    "kalish_optimal_two_point_logistic(x, y)\n",
    "white_optimal_two_point_logistic(x, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5u6neVBsyq_H",
    "outputId": "9b65c370-4353-4fa2-bddc-c0e0eb78aad9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5cm9m0bhrzg",
    "outputId": "4900a1c1-2946-47ad-d5dc-fdb40783708e"
   },
   "source": [
    "%%R\n",
    "filter(res_JS_normal_approx_jacobian, signal_nrow == 800)$empirical_delta_PT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "kM_ZWyZOiEf6",
    "outputId": "c308b96e-3385-4203-d094-50c4294a4216"
   },
   "source": [
    "%%R\n",
    "g4 <- ggplot(dplyr::filter(res_JS_normal_approx_jacobian, signal_nrow == 400), aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"final rel err\")) +\n",
    "      # geom_line(data = res_normal_bayes_approx_jacobian, aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))\n",
    "      geom_line(data = dplyr::filter(res_JS_normal_approx_jacobian_min, signal_nrow == 400), aes(x = sparsity, y = empirical_delta_PT, color = \"min rel err\"))+\n",
    "      # geom_line(aes(x = sparsity, y = sparsity, color = \"diagonal\"))\n",
    "      scale_color_discrete(name = \"Threshold 1e-1\")\n",
    "g4"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IREoW-z6b8ka",
    "outputId": "053c9c1a-6fe6-498b-b1fb-cd4a102b3f4a"
   },
   "source": [
    "%%R\n",
    "g4 <- ggplot(dplyr::filter(res_JS_normal_approx_jacobian, signal_nrow == 400), aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"final rel err\")) +\n",
    "      # geom_line(data = res_normal_bayes_approx_jacobian, aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))\n",
    "      geom_line(data = dplyr::filter(res_JS_normal_approx_jacobian_min, signal_nrow == 400), aes(x = sparsity, y = empirical_delta_PT, color = \"min rel err\"))+\n",
    "      # geom_line(aes(x = sparsity, y = sparsity, color = \"diagonal\"))\n",
    "      scale_color_discrete(name = \"Threshold 1e-1\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJfe17pDb8ZM"
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5r2GjD8SI1Q",
    "outputId": "776d574e-a8a6-49aa-a10a-730e32ac55a6"
   },
   "source": [
    "# risk of positive part james stein estimator at 0\n",
    "%%R\n",
    "JS_risk_at_zero = function(d){\n",
    "    integrand = function(x){\n",
    "        return((1-((d-2)/x))^2*x*dchisq(x, d))\n",
    "    }\n",
    "    return(integrate(integrand, d-2, Inf)$value/d)\n",
    "}\n",
    "\n",
    "predicted_JS_PT = function(sparsity, d){\n",
    "    return(sparsity + ((1-sparsity)*JS_risk_at_zero(d)))\n",
    "}\n",
    "\n",
    "predicted_JS_PT(0.3, 5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDg3Q8uSXL84"
   },
   "source": [
    "%%R\n",
    "# James Stein\n",
    "res_JS_normal_regenerated = res_JS_normal_regenerated %>%\n",
    "mutate(pred_JS_PT = mapply(predicted_JS_PT, sparsity, signal_ncol))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lAIT-01S_pZ",
    "outputId": "4ac2c75a-ffc9-46dc-9723-7f84a2177b7b"
   },
   "source": [
    "%%R\n",
    "f = function(tau, x, y){\n",
    "    logreg = glm(y~x, family = binomial(link = \"logit\"))\n",
    "    intercept = logreg$coefficients[1]\n",
    "    slope = logreg$coefficients[2]\n",
    "    return(tau + log(tau/(1-tau))/slope +intercept/slope - log(sum(y == 1)/sum(y == 0))/slope)\n",
    "}\n",
    "\n",
    "\n",
    "uniroot(f, c(0, 1), x = x, y = y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEuEC-h_UdcN"
   },
   "source": [
    "%%R\n",
    "# JS upper bound (risk of OG JS, not positive part)\n",
    "predicted_JS_upper_bound = function(sparsity, signal_ncol){\n",
    "    return((1-sparsity)*2/signal_ncol + sparsity)\n",
    "}\n",
    "\n",
    "# JS approximate by taking upto 1st leading order term from asymptotic expansion\n",
    "predicted_JS_approx_1st = function(sparsity, signal_ncol){\n",
    "    return((1-sparsity)*(1/signal_ncol) + sparsity)\n",
    "}\n",
    "\n",
    "# JS approximate by taking upto 2nd leading order term from asymptotic expansion\n",
    "predicted_JS_approx_2nd = function(sparsity, signal_ncol){\n",
    "    return((1-sparsity)*(1/signal_ncol + 0.752/signal_ncol^(3/2)) + sparsity)\n",
    "}\n",
    "\n",
    "res_normal_js = res_normal_js %>%\n",
    "mutate(pred_JS_upper_bound = mapply(predicted_JS_upper_bound, sparsity, signal_ncol)) %>%\n",
    "mutate(pred_JS_approx_2nd = mapply(predicted_JS_approx_2nd, sparsity, signal_ncol)) %>%\n",
    "mutate(pred_JS_approx_1st = mapply(predicted_JS_approx_1st, sparsity, signal_ncol))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbArnBypZxho"
   },
   "source": [
    "%%R\n",
    "# convex optimization / blocksoft\n",
    "res_normal_js = res_normal_js %>%\n",
    "mutate(pred_blocksoft_PT = mapply(predicted_delta_PT, sparsity, signal_ncol))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vULS0Pz8-FmA"
   },
   "source": [
    "%%R\n",
    "# Important: don't run this!\n",
    "head(res)\n",
    "# write.csv(res, \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_integer_scale.csv\")\n",
    "# write.csv(res, \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_AMP_blocksoft_threshold_corrected.csv\")\n",
    "# write.csv(res, \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_AMP_blocksoft_larger.csv\")\n",
    "# write.csv(res, \"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_integer_scale_corrected.csv\")\n",
    "write.csv(res, \"PT_data_comr.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "enB3KflaHNfv",
    "outputId": "58275268-81fe-4be2-d813-482703d7cd81"
   },
   "source": [
    "%%R\n",
    "B = 3\n",
    "df1 = read.csv(\"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_integer_scale_corrected.csv\", row.names = 1)\n",
    "# df2 = read.csv(\"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_AMP_blocksoft_larger.csv\", row.names = 1)\n",
    "df2 = res\n",
    "\n",
    "df1_100 = df1 %>% filter(signal_ncol == B)\n",
    "df2_small = df2 %>% filter(signal_ncol == B)\n",
    "g3 <- ggplot(df1_100, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"Phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))+\n",
    "    scale_color_discrete(name = \"no. of rows of signal\") +\n",
    "    geom_line(aes(x = sparsity, y = pred_delta_PT), color = \"black\") +\n",
    "    geom_line(data = df2_small, aes(x = sparsity, y = empirical_delta_PT), color = \"brown\")\n",
    "\n",
    "g3"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "Y_8retUL2840",
    "outputId": "0cc81e29-0bce-4a41-ddc8-391d0ad20dab"
   },
   "source": [
    "%%R\n",
    "B = 4\n",
    "res_small = res %>% filter(signal_ncol == B)\n",
    "g2 <- ggplot(res_small, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"Phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))+\n",
    "    scale_color_discrete(name = \"no. of rows of signal\", labels = c(\"400\", \"800\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_delta_PT), color = \"black\")\n",
    "\n",
    "g2\n",
    "\n",
    "# ggsave(paste(\"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_PT_plot_B=\", B, \".png\", sep = \"\"), g2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "aIybuSEkE4Ke",
    "outputId": "9f9cf92c-32d3-4588-f054-1799a97a49e1"
   },
   "source": [
    "%%R\n",
    "B = 5\n",
    "g2 <- ggplot(res_normal, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"AMP phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"normal\"))+\n",
    "    geom_line(data = res_poisson, aes(x = sparsity, y = empirical_delta_PT, color = \"poisson\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_delta_PT, color = \"predicted\")) +\n",
    "    scale_color_discrete(name = \"signal distribution\")\n",
    "g2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "halSehQyStEw"
   },
   "source": [
    "%%R\n",
    "dat = read.csv('normal_bayes_PT.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "X_EGH6f_cRba",
    "outputId": "5b0337e6-822b-42ae-a0c7-b46c463b5a47"
   },
   "source": [
    "%%R\n",
    "g4 <- ggplot(res_JS_normal_800, aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"full jacobian\"))+\n",
    "      geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"predicted\")) +\n",
    "      geom_line(data = dat, aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))\n",
    "      # geom_line(aes(x = sparsity, y = sparsity, color = \"diagonal\"))\n",
    "g4"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "ZsU0I96CZuK9",
    "outputId": "15cc2fa8-3414-428e-8835-54056b981beb"
   },
   "source": [
    "%%R\n",
    "g4 <- ggplot(res_JS_normal_800, aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"full jacobian\"))+\n",
    "      # geom_line(data = res_normal_bayes_approx_jacobian, aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))\n",
    "      geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"JS MSE curve\")) +\n",
    "      geom_line(data = res_JS_normal_approx_jacobian, aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow)))\n",
    "g4"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IY1_tWQ_aFsF",
    "outputId": "18c6daf5-de60-42df-9be1-2a33e85d9bea"
   },
   "source": [
    "%%R\n",
    "dat = dplyr::filter(res_JS_normal_approx_jacobian, signal_nrow %in% c(400, 800))\n",
    "dat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "9M8uMMOZagfo",
    "outputId": "250c1b47-7061-4615-a899-f35ff9c39960"
   },
   "source": [
    "%%R\n",
    "g4 <- ggplot(dat, aes(x = sparsity, y = delta)) +\n",
    "      geom_line(aes(x = sparsity, y = empirical_delta_PT, color = as.factor(signal_nrow))) +\n",
    "      geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"JS MSE curve\"))\n",
    "g4"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGLewlNgaqzO"
   },
   "source": [
    "%%R\n",
    "write.csv(dat, \"temp.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "320x_KmOSde5",
    "outputId": "7781e1f1-a816-40ad-dfa7-19c49cfb52c0"
   },
   "source": [
    "%%R\n",
    "# james stein plot\n",
    "B = 5\n",
    "g2 <- ggplot(res_poisson_js, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"AMP phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"poisson, N = 400, JS\"))+\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"JS prediction from scalar SE\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_blocksoft_PT, color = \"blocksoft prediction from scalar SE\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_upper_bound, color = \"JS upper bound\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_approx_1st, color = \"JS approximate (1st order)\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_approx_2nd, color = \"JS approximate (2nd order)\")) +\n",
    "    geom_line(data = res_poisson_bs, aes(x = sparsity, y = empirical_delta_PT, color = \"poisson, N = 400, blocksoft\"))+\n",
    "    geom_line(data = res_normal_bs, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, blocksoft\"))+\n",
    "    geom_line(data = res_normal_bayes, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 200, bayes\"))+\n",
    "    scale_color_discrete(name = \"signal distribution\")\n",
    "g2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "mnKD_Xrzd09Y",
    "outputId": "cdfb7e91-234b-41fb-8a8e-341e1f0cc81f"
   },
   "source": [
    "%%R\n",
    "# james stein plot\n",
    "B = 5\n",
    "g2 <- ggplot(res_poisson_js, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"AMP phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"poisson, N = 400, JS\"))+\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"JS prediction from scalar SE\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_blocksoft_PT, color = \"blocksoft prediction from scalar SE\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_upper_bound, color = \"JS upper bound\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_approx_1st, color = \"JS approximate (1st order)\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_approx_2nd, color = \"JS approximate (2nd order)\")) +\n",
    "    geom_line(data = res_normal_js, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, JS\"))+\n",
    "    scale_color_discrete(name = \"signal distribution\")\n",
    "g2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sv7RvGtgTU8c"
   },
   "source": [
    "%%R\n",
    "write.csv(res, \"temp.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "rQvJC1rNXMdz",
    "outputId": "70236410-9b2b-46db-ef7d-03939da5d210"
   },
   "source": [
    "AMP_PT_df = pd.read_csv(\"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_AMP_blocksoft.csv\", index_col = 0)\n",
    "AMP_PT_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juDuLEhphQuH",
    "outputId": "d8317c8c-22ac-4b76-be18-12c448c3bc1d"
   },
   "source": [
    "def update_undersampling_int_grid(PT_df, signal_nrow, signal_ncol, nonzero_rows):\n",
    "\n",
    "  empirical_PT_row = PT_df[(PT_df['signal_nrow'] == signal_nrow) & (PT_df['signal_ncol'] == signal_ncol) & (PT_df['nonzero_rows'] == nonzero_rows)]\n",
    "  empirical_PT = empirical_PT_row['empirical_delta_PT'].item()\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, empirical_PT - 0.1)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, empirical_PT + 0.1)))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "# update_undersampling_int_grid(empirical_PT_df, 50, 5, 4)\n",
    "update_undersampling_int_grid(AMP_PT_df, 100, 2, 20)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "innDBhQe7WHx",
    "outputId": "dfcf18fa-a752-4290-c12c-8306e50b0769"
   },
   "source": [
    "# coarser sparsity grid\n",
    "\n",
    "def update_undersampling_int_grid_coarse(PT_df, signal_nrow, signal_ncol, sparsity):\n",
    "\n",
    "  empirical_PT_row = PT_df[(PT_df['signal_nrow'] == signal_nrow) & (PT_df['B'] == signal_ncol) & (PT_df['sparsity'] == sparsity)]\n",
    "  empirical_PT = empirical_PT_row['empirical_delta_PT'].item()\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, empirical_PT - 0.1)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, empirical_PT + 0.1)))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "update_undersampling_int_grid_coarse(empirical_PT_df, 200, 1, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "KyxTMghyUrNx",
    "outputId": "5ed783e5-0d7d-48ac-b361-2643da58e7d5"
   },
   "source": [
    "PT_df = pd.read_csv(\"/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/PT_data_integer_scale.csv\", index_col = 0)\n",
    "PT_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Block soft thresholding"
   ],
   "metadata": {
    "id": "UIk2eCEzkGj2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PT_df = pd.read_csv(\"blocksoft_minimax_risk.csv\")\n",
    "PT_df.head(3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "vK8VZ-pinZ6X",
    "outputId": "7657e39b-169f-46cf-aa00-aff3d075c131"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cB4tsnmoT-xA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0e2f4ce5-81a6-44a0-deb3-d6dd5f78a9b9"
   },
   "source": [
    "# coarser sparsity grid: undersampling based on predicted\n",
    "\n",
    "def update_undersampling_int_grid_coarse_pred(PT_df, signal_nrow, signal_ncol, sparsity, band_half_width):\n",
    "  PT_row = PT_df[(PT_df['signal_ncol'] == signal_ncol) & (PT_df['sparsity_values'] == sparsity)]\n",
    "  PT = PT_row['predicted_delta_PT_values'].item()\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, PT - band_half_width)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, PT + band_half_width)))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "update_undersampling_int_grid_coarse_pred(PT_df, 400, 5, 0.1, 0.1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# coarser sparsity grid: undersampling based on predicted\n",
    "\n",
    "def update_undersampling_int_grid_coarse_upper(PT_df, signal_nrow, signal_ncol, sparsity, band_upper_width):\n",
    "  PT_row = PT_df[(PT_df['signal_ncol'] == signal_ncol) & (PT_df['sparsity_values'] == sparsity)]\n",
    "  PT = PT_row['predicted_delta_PT_values'].item()\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, PT)))\n",
    "  undersampling_int_upper = int(signal_nrow * min(1, PT + band_upper_width))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "update_undersampling_int_grid_coarse_pred(PT_df, 800, 5, 0.95, 0.1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySG3sk9q_EIP",
    "outputId": "f880af44-12e4-4b6e-937c-b88a5be89481"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt-WRx7BdyEN"
   },
   "source": [
    "def dict_experiment(PT_df) -> dict:\n",
    "  total_params = 0\n",
    "  # exp = dict(table_name='AMP_matrix_recovery_blocksoft_25_test',\n",
    "  #            base_index=0,\n",
    "  #            db_url='sqlite:///data/EMS.db3',\n",
    "  #            multi_res=[])\n",
    "  # mr = exp['multi_res']\n",
    "  # signal_nrow_grid = [100]\n",
    "  # signal_ncol_grid = [3, 4, 5]\n",
    "  # nonzero_rows_grid = [5, 10, 15]\n",
    "  # for signal_nrow in signal_nrow_grid:\n",
    "  #   for signal_ncol in signal_ncol_grid:\n",
    "  #     for nonzero_rows in nonzero_rows_grid: #np.arange(1, signal_nrow):\n",
    "  #       d = {\n",
    "  #           'nonzero_rows': [round(nonzero_rows)],\n",
    "  #           'num_measurements': [round(x) for x in np.linspace(5, 95, num = 19)], #[round(x) for x in np.arange(1, signal_nrow)],\n",
    "  #           'signal_nrow': [round(signal_nrow)],\n",
    "  #           'signal_ncol': [round(signal_ncol)],\n",
    "  #           'mc': list(range(20)),\n",
    "  #           'max_iter': [500],\n",
    "  #           'err_tol': [1e-5],\n",
    "  #           'sparsity_tol': [1e-4],\n",
    "  #           'err_explosion_tol': [100]\n",
    "  #           }\n",
    "  #       mr.append(d)\n",
    "\n",
    "  # exp = dict(table_name='AMP_matrix_recovery_blocksoft_09',\n",
    "  #            base_index=0,\n",
    "  #            db_url='sqlite:///data/EMS.db3',\n",
    "  #            multi_res=[])\n",
    "  # mr = exp['multi_res']\n",
    "  # signal_nrow_grid = [100]\n",
    "  # signal_ncol_grid = [3, 4, 5]\n",
    "  # nonzero_rows_grid = np.linspace(5, 95, num = 19)\n",
    "  # for signal_nrow in signal_nrow_grid:\n",
    "  #   for signal_ncol in signal_ncol_grid:\n",
    "  #     for nonzero_rows in nonzero_rows_grid: #np.arange(1, signal_nrow):\n",
    "  #       d = {\n",
    "  #           'nonzero_rows': [round(nonzero_rows)],\n",
    "  #           'num_measurements': [round(x) for x in np.arange(1, signal_nrow)], #[round(x) for x in np.arange(1, signal_nrow)],\n",
    "  #           'signal_nrow': [round(signal_nrow)],\n",
    "  #           'signal_ncol': [round(signal_ncol)],\n",
    "  #           'mc': list(range(50)),\n",
    "  #           'max_iter': [500],\n",
    "  #           'err_tol': [1e-5],\n",
    "  #           'sparsity_tol': [1e-4],\n",
    "  #           'err_explosion_tol': [100]\n",
    "  #           }\n",
    "  #       mr.append(d)\n",
    "\n",
    "  exp = dict(table_name='comr-N50-larger-grids',\n",
    "             base_index=0,\n",
    "             db_url='sqlite:///data/EMS.db3',\n",
    "             multi_res=[])\n",
    "  mr = exp['multi_res']\n",
    "  signal_nrow_grid = [400, 800]\n",
    "  signal_ncol_grid = [1, 2, 3, 4, 5]\n",
    "  sparsity_grid = [round(x, 2) for x in np.linspace(0.02, 0.98, num = 49)]\n",
    "  for signal_nrow in signal_nrow_grid:\n",
    "    for signal_ncol in signal_ncol_grid:\n",
    "      for sparsity in sparsity_grid:\n",
    "        d = {\n",
    "            'nonzero_rows': [round(signal_nrow * sparsity)],\n",
    "            'num_measurements': [round(x) for x in update_undersampling_int_grid_coarse_pred(PT_df, signal_nrow, signal_ncol, sparsity, band_half_width =0.05)],\n",
    "            # 'num_measurements': [round(x) for x in [signal_nrow/4, signal_nrow/3, signal_nrow/2, signal_nrow*(2/3), signal_nrow*(3/4)]],\n",
    "            'signal_nrow': [round(signal_nrow)],\n",
    "            'signal_ncol': [round(signal_ncol)],\n",
    "            'mc': list(range(50)),\n",
    "            'err_tol': [1e-5],\n",
    "            'sparsity_tol': [1e-4]\n",
    "            }\n",
    "        mr.append(d)\n",
    "        total_params = total_params + len(d['num_measurements'])*len(d['mc'])\n",
    "  print(total_params)\n",
    "\n",
    "  # Following actually sent for computation\n",
    "  # exp = dict(table_name='AMP_matrix_recovery_blocksoft_02',\n",
    "  #            base_index=0,\n",
    "  #            db_url='sqlite:///data/EMS.db3',\n",
    "  #            multi_res=[])\n",
    "  # mr = exp['multi_res']\n",
    "  # signal_nrow_grid = [100]\n",
    "  # signal_ncol_grid = [1, 2, 3, 4, 5]\n",
    "  # for signal_nrow in signal_nrow_grid:\n",
    "  #   for signal_ncol in signal_ncol_grid:\n",
    "  #     for nonzero_rows in [20]:\n",
    "  #       d = {\n",
    "  #           'nonzero_rows': [round(nonzero_rows)],\n",
    "  #           'num_measurements': [round(x) for x in update_undersampling_int_grid(PT_df, signal_nrow, signal_ncol, nonzero_rows)],\n",
    "  #           'signal_nrow': [round(signal_nrow)],\n",
    "  #           'signal_ncol': [round(signal_ncol)],\n",
    "  #           'mc': list(range(50)),\n",
    "  #           'max_iter': [500],\n",
    "  #           'err_tol': [1e-5],\n",
    "  #           'sparsity_tol': [1e-4],\n",
    "  #           'err_explosion_tol': [100]\n",
    "  #           }\n",
    "  #       mr.append(d)\n",
    "\n",
    "  # exp = dict(table_name='AMP_matrix_recovery_blocksoft_02',\n",
    "  #            base_index=0,\n",
    "  #            db_url='sqlite:///data/EMS.db3',\n",
    "  #            multi_res=[])\n",
    "  # mr = exp['multi_res']\n",
    "  # signal_nrow_grid = [100]\n",
    "  # signal_ncol_grid = [1, 2, 3, 4, 5]\n",
    "  # for signal_nrow in signal_nrow_grid:\n",
    "  #   for signal_ncol in signal_ncol_grid:\n",
    "  #     for nonzero_rows in np.arange(5, signal_nrow, step = 5):\n",
    "  #       d = {\n",
    "  #           'nonzero_rows': [round(nonzero_rows)],\n",
    "  #           'num_measurements': [round(x) for x in np.arange(5, signal_nrow, step = 5)],\n",
    "  #           'signal_nrow': [round(signal_nrow)],\n",
    "  #           'signal_ncol': [round(signal_ncol)],\n",
    "  #           'mc': list(range(70)),\n",
    "  #           'max_iter': [500],\n",
    "  #           'err_tol': [1e-5],\n",
    "  #           'sparsity_tol': [1e-4],\n",
    "  #           'err_explosion_tol': [100]\n",
    "  #           }\n",
    "  #       mr.append(d)\n",
    "\n",
    "  # signal_nrow_grid = [200]\n",
    "  # signal_ncol_grid = [1, 2, 3, 4, 5]\n",
    "  # sparsity_grid = [round(x, 2) for x in np.linspace(0.01, 0.99, 99)]\n",
    "  # for signal_nrow in signal_nrow_grid:\n",
    "  #   for signal_ncol in signal_ncol_grid:\n",
    "  #     for sparsity in sparsity_grid:\n",
    "  #       d = {\n",
    "  #           'signal_nrow': [round(signal_nrow)],\n",
    "  #           'signal_ncol': [round(signal_ncol)],\n",
    "  #           'nonzero_rows': [round(signal_nrow * sparsity)],\n",
    "  #           'num_measurements': [round(x) for x in update_undersampling_int_grid_coarse(PT_df, signal_nrow, signal_ncol, sparsity)],\n",
    "  #           'mc': list(range(100)),\n",
    "  #           'err_tol': [1e-5],\n",
    "  #           'sparsity_tol': [1e-4]\n",
    "  #           }\n",
    "  #       mr.append(d)\n",
    "  #       total_params = total_params + len(d['num_measurements'])\n",
    "  # print(total_params)\n",
    "  return exp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def dict_experiment(PT_df) -> dict:\n",
    "  total_params = 0\n",
    "\n",
    "  exp = dict(table_name='AMP_matrix_recovery_blocksoft_approx_jacobian_poisson_jit',\n",
    "             base_index=0,\n",
    "             description='Performs 50 mc runs at integer undersampling point in the grid of upper-width 0.15 above predicted undersampling point, with blocksoft denoiser. Sparsity varies from 0.05 to 0.95 in interval of 0.05. No. of rows varies in [800, 1600] and no. of columns is 5. cov(resid) used to estimate the noise covariance at each iteration instead of resid.T * resid/n.',\n",
    "             db_url='sqlite:///data/EMS.db3',\n",
    "             multi_res=[])\n",
    "  mr = exp['multi_res']\n",
    "  signal_nrow_grid = [800, 1600]\n",
    "  signal_ncol_grid = [5]\n",
    "  sparsity_grid = [round(x, 2) for x in np.linspace(0.05, 0.95, num = 19)]\n",
    "  for signal_nrow in signal_nrow_grid:\n",
    "    for signal_ncol in signal_ncol_grid:\n",
    "      for sparsity in sparsity_grid:\n",
    "        d = {\n",
    "            'nonzero_rows': [round(signal_nrow * sparsity)],\n",
    "            'num_measurements': [round(x) for x in update_undersampling_int_grid_coarse_upper(PT_df, signal_nrow, signal_ncol, sparsity, band_upper_width =0.15)],\n",
    "            # 'num_measurements': [round(x) for x in [signal_nrow/4, signal_nrow/3, signal_nrow/2, signal_nrow*(2/3), signal_nrow*(3/4)]],\n",
    "            'signal_nrow': [round(signal_nrow)],\n",
    "            'signal_ncol': [round(signal_ncol)],\n",
    "            'max_iter': [500],\n",
    "            'err_tol': [1e-5],\n",
    "            'sparsity_tol': [1e-4],\n",
    "            'err_explosion_tol': [100],\n",
    "            'mc': list(range(50)),\n",
    "            'selected_rows_frac': [1.0]\n",
    "            }\n",
    "        mr.append(d)\n",
    "        total_params = total_params + len(d['num_measurements'])*len(d['mc'])\n",
    "  print(total_params)\n",
    "  return exp"
   ],
   "metadata": {
    "id": "UrjVtl_1oTt-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbDgebl-fyUu",
    "outputId": "c4f906e5-02bb-46f9-f335-575169e39aff"
   },
   "source": [
    "# real experiment json creation\n",
    "def dict_experiment_json(PT_df):\n",
    "  exp = dict_experiment(PT_df)\n",
    "  # with open('/content/drive/MyDrive/Andrew+Apratim+Dave/experimental_design/AMP_matrix_recovery_0002.json', 'w') as json_file:\n",
    "  #   json.dump(exp, json_file, indent = 4)\n",
    "  with open('AMP_matrix_recovery_blocksoft_approx_jacobian_poisson_jit.json', 'w') as json_file:\n",
    "      json.dump(exp, json_file, indent = 4)\n",
    "\n",
    "dict_experiment_json(PT_df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLLXv1QoofO1",
    "outputId": "a844b136-f2b9-4ff2-b0d1-8029a357f8f2"
   },
   "source": [
    "# test experiment json creation\n",
    "def test_experiment_json():\n",
    "  exp = dict_experiment(1)\n",
    "  with open('updated_undersampling_int_grids_test.json', 'w') as json_file:\n",
    "    json.dump(exp, json_file, indent = 4)\n",
    "\n",
    "test_experiment_json()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pg-7_oRMC6uN"
   },
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9zn_W06o5SV",
    "outputId": "200e3ae5-d104-4689-d963-aea120c92a27"
   },
   "source": [
    "np.arange(5, 100, step = 5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-ypNNNtZWHc"
   },
   "source": [
    "AMP_raw_data = get_df_from_project('hs-deep-lab-donoho', 'EMS.AMP_matrix_recovery_blocksoft_02')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "ZLrNTreYDJp-",
    "outputId": "bd8418f8-2603-4d3c-bb1c-a58c9e58216c"
   },
   "source": [
    "df_small = AMP_raw_data[AMP_raw_data['nonzero_rows'] == 20]\n",
    "df_small"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Tg0Q0AQDXmS",
    "outputId": "9adf8e9d-b5a1-4d93-c4a5-f494bb29d99a"
   },
   "source": [
    "from scipy import integrate\n",
    "from scipy.stats import chi2\n",
    "from scipy.optimize import brentq\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def h_deno_integrand(x, tau, signal_ncol):\n",
    "    return  (np.sqrt(x) - tau) * chi2.pdf(x, df = signal_ncol)\n",
    "\n",
    "\n",
    "def h_deno_integral(tau, signal_ncol):\n",
    "    return max(1e-10, integrate.quad(h_deno_integrand, tau**2, np.inf, args=(tau, signal_ncol))[0])\n",
    "\n",
    "\n",
    "def h(tau, signal_ncol):\n",
    "    numerator = tau\n",
    "    denominator = h_deno_integral(tau, signal_ncol)\n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "def h_centered(tau, sparsity, signal_ncol):\n",
    "    return h(tau, signal_ncol) + 1 - (1/sparsity)\n",
    "\n",
    "\n",
    "def minimax_tau_threshold(sparsity, signal_ncol):\n",
    "    #root = newton(h_centered, 0, args=(sparsity, signal_ncol), maxiter = 1000, full_output=True)\n",
    "    #root = fsolve(func = h_centered, x0 = -2, args = (sparsity, signal_ncol))\n",
    "    root = brentq(h_centered, 0, 1e+10, args = (sparsity, signal_ncol))\n",
    "    return root\n",
    "\n",
    "def minimax_tau_threshold_approx(sparsity, signal_ncol):\n",
    "    return (1-sparsity)*np.sqrt(signal_ncol)\n",
    "\n",
    "minimax_tau_threshold(0.2, 10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating data file with blocksoft minimax risk values"
   ],
   "metadata": {
    "id": "cOCmXYnzmjn0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOdz3SxcEM_W"
   },
   "source": [
    "%%R\n",
    "#blocksoft thresholding minimax risk\n",
    "deno_integrand = function(x, B, tau_sq){\n",
    "    tau = sqrt(tau_sq)\n",
    "    return((sqrt(x) - tau)*dchisq(x, B))\n",
    "}\n",
    "\n",
    "deno_integral = function(B, tau_sq){\n",
    "    return(integrate(deno_integrand, lower = tau_sq, upper = Inf, B, tau_sq)$value)\n",
    "}\n",
    "\n",
    "num_integrand = function(x, B, tau_sq){\n",
    "    tau = sqrt(tau_sq)\n",
    "    return((sqrt(x) - tau)^2*dchisq(x, B))\n",
    "}\n",
    "\n",
    "num_integral = function(B, tau_sq){\n",
    "    return(integrate(num_integrand, lower = tau_sq, upper = Inf, B, tau_sq)$value)\n",
    "}\n",
    "\n",
    "h = function(B, tau_sq){\n",
    "    return(sqrt(tau_sq)/deno_integral(B, tau_sq))\n",
    "}\n",
    "\n",
    "g = function(B, tau_sq){\n",
    "    return(sqrt(tau_sq)*num_integral(B, tau_sq)/deno_integral(B, tau_sq))\n",
    "}\n",
    "\n",
    "tau_sq_optim_eqn = function(tau_sq, sparsity, B){\n",
    "    return(h(B, tau_sq)+1-(1/sparsity))\n",
    "}\n",
    "\n",
    "#giving a huge upper bound 1e+50 instead of Inf as otherwise uniroot function breaks\n",
    "tau_sq_optim = function(sparsity, B){\n",
    "    res = uniroot(tau_sq_optim_eqn, c(0, 1e+100), sparsity, B)$root\n",
    "    return(res)\n",
    "}\n",
    "\n",
    "#main function delivering delta PT value for given sparsity and B\n",
    "predicted_delta_PT = function(sparsity, B){\n",
    "    tau_sq = tau_sq_optim(sparsity, B)\n",
    "    return((B+tau_sq+g(B, tau_sq))/(B*(1+h(B, tau_sq))))\n",
    "}\n",
    "\n",
    "sparsity_values = seq(0.05, 0.95, by = 0.05)\n",
    "predicted_delta_PT_values = sapply(sparsity_values, predicted_delta_PT, B = 5)\n",
    "df = data.frame(sparsity_values, signal_ncol = 5, predicted_delta_PT_values)\n",
    "write.csv(df, \"blocksoft_minimax_risk.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "5izBRtBBUbHC",
    "outputId": "30cb2385-8d42-464c-f1bd-2044777b7df2"
   },
   "source": [
    "df = pd.read_csv(\"blocksoft_minimax_risk.csv\")\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZxhZoZkWxyf"
   },
   "source": [
    "# Subsetting from exisiting database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--xgXaNHEsiV"
   },
   "source": [
    "From comr database, select the rows with signal_nrow = 400 and signal_ncol = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0MfY-CNUevO",
    "outputId": "91d580f1-8deb-4f61-bdf8-84b07118d1b7"
   },
   "source": [
    "df = get_df_from_project('hs-deep-lab-donoho', 'EMS.comr-N50-larger-grids')\n",
    "df_small = df[(df['signal_nrow'].isin([400])) & (df['signal_ncol'] == 5)]\n",
    "df_small.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go7I-X9aEmwv"
   },
   "source": [
    "Select 50% rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlvcAcjrEnKR"
   },
   "source": [
    "num_rows = int(0.5 * df_small.shape[0])\n",
    "np.random.seed(123456)\n",
    "select_indices = np.random.choice(range(df_small.shape[0]), num_rows, replace = False)\n",
    "df_small_select = df_small.iloc[select_indices]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFwwTIhUGz3t"
   },
   "source": [
    "From this small df, extract the params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyIjxcNLGDci"
   },
   "source": [
    "def dict_experiment_subset(df_small_select) -> dict:\n",
    "  total_params = 0\n",
    "  exp = dict(table_name='AMP_matrix_recovery_blocksoft_10_normal',\n",
    "             description='Randomly samples 50% rows from convex optimization database with signal rows 400 and 5 columns. Full jacobian computation. Seed = 123456',\n",
    "             base_index=0,\n",
    "             db_url='sqlite:///data/EMS.db3',\n",
    "             multi_res=[])\n",
    "  mr = exp['multi_res']\n",
    "  for k in range(df_small_select.shape[0]):\n",
    "    df_row = df_small_select.iloc[k]\n",
    "    d = {\n",
    "        'nonzero_rows': [round(df_row['nonzero_rows'].item())],\n",
    "        'num_measurements': [round(df_row['num_measurements'].item())],\n",
    "        'signal_nrow': [round(df_row['signal_nrow'].item())],\n",
    "        'signal_ncol': [round(df_row['signal_ncol'].item())],\n",
    "        'mc': [round(df_row['mc'].item())],\n",
    "        'max_iter': [round(500)],\n",
    "        'err_tol': [df_row['err_tol'].item()],\n",
    "        'sparsity_tol': [df_row['sparsity_tol'].item()],\n",
    "        'err_explosion_tol': [100.0]\n",
    "        }\n",
    "    mr.append(d)\n",
    "    total_params = total_params + 1\n",
    "  print(total_params)\n",
    "\n",
    "  return exp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycoWW_MyGPNl",
    "outputId": "6106a208-a0a8-410a-9fa7-732a0a505e66"
   },
   "source": [
    "# real experiment json creation\n",
    "def dict_experiment_json_subset(df_small_select):\n",
    "  exp = dict_experiment_subset(df_small_select)\n",
    "  with open('AMP_matrix_recovery_blocksoft_11_normal.json', 'w') as json_file:\n",
    "      json.dump(exp, json_file, indent = 4)\n",
    "\n",
    "dict_experiment_json_subset(df_small_select)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9UfuTlAvdUD"
   },
   "source": [
    "# James Stein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv6Zons2vfUK",
    "outputId": "7225f979-a88e-407f-a0de-b8c8bfccef8f"
   },
   "source": [
    "# risk of positive part james stein estimator at 0\n",
    "%%R\n",
    "JS_risk_at_zero = function(d){\n",
    "    integrand = function(x){\n",
    "        return((1-((d-2)/x))^2*x*dchisq(x, d))\n",
    "    }\n",
    "    return(integrate(integrand, d-2, Inf)$value/d)\n",
    "}\n",
    "\n",
    "JS_sparse_minimax_risk = function(sparsity, d){\n",
    "    return(sparsity + ((1-sparsity)*JS_risk_at_zero(d)))\n",
    "}\n",
    "\n",
    "JS_sparse_minimax_risk(0.2, 5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfAqcMw56lMy",
    "outputId": "56c21d74-63b1-4402-d38a-0308d30f860f"
   },
   "source": [
    "from scipy import integrate\n",
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def integrand(x, signal_ncol):\n",
    "    return  (1 - ((signal_ncol-2)/x))**2 * x * chi2.pdf(x, df = signal_ncol)\n",
    "\n",
    "\n",
    "def JS_risk_at_zero(signal_ncol):\n",
    "    return integrate.quad(integrand, signal_ncol-2, np.inf, args=signal_ncol)[0]/signal_ncol\n",
    "\n",
    "\n",
    "def JS_sparse_minimax_risk(sparsity, signal_ncol):\n",
    "  return sparsity + (1-sparsity)*JS_risk_at_zero(signal_ncol)\n",
    "\n",
    "\n",
    "JS_sparse_minimax_risk(0.2, 5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sfeeuj5y5b0_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "50c8fb7f-b599-4469-87b3-dc3f71a9c499"
   },
   "source": [
    "# coarser sparsity grid: undersampling based on predicted\n",
    "def update_undersampling_int_grid_coarse_pred(signal_nrow, signal_ncol, sparsity, band_half_width):\n",
    "  PT = JS_sparse_minimax_risk(sparsity, signal_ncol)\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, PT - band_half_width)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, PT + band_half_width)))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "update_undersampling_int_grid_coarse_pred(400, 10, 0.01, 0.05)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PTsoKMRT3zR"
   },
   "source": [
    "# CAUTION!\n",
    "# below the predicted MSE curve, we have seen PT does not occur. So only 0.1 total length above PT will be considered.\n",
    "\n",
    "# coarser sparsity grid: undersampling based on predicted\n",
    "def update_undersampling_int_grid_coarse_pred_modified(signal_nrow, signal_ncol, sparsity, band_upper_width):\n",
    "  PT = JS_sparse_minimax_risk(sparsity, signal_ncol)\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, PT)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, PT + band_upper_width)))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "update_undersampling_int_grid_coarse_pred(400, 10, 0.01, 0.05)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAtt7RSj4KDt"
   },
   "source": [
    "# james stein experiment dicts\n",
    "def dict_experiment(PT_df) -> dict:\n",
    "  total_params = 0\n",
    "  exp = dict(table_name='just_test',\n",
    "             base_index=0,\n",
    "             description='Performs 50 mc runs at integer undersampling point in the grid of width 0.15 above predicted undersampling point, with james stein denoiser. Sparsity varies from 0.05 to 0.95 in interval of 0.05. No. of rows varies in [4000] and no. of columns is 5. Measurement matrix and observation regenerated at every iteration. cov(resid) used to estimate the noise covariance at each iteration instead of resid.T * resid/n.',\n",
    "             db_url='sqlite:///data/EMS.db3',\n",
    "             multi_res=[])\n",
    "  mr = exp['multi_res']\n",
    "  signal_nrow_grid = [400]\n",
    "  signal_ncol_grid = [5]\n",
    "  sparsity_grid = [round(x, 2) for x in np.linspace(0.05, 0.95, num = 1)]\n",
    "  # sparsity_grid = [round(0.3, 2)]\n",
    "  for signal_nrow in signal_nrow_grid:\n",
    "    for signal_ncol in signal_ncol_grid:\n",
    "      for sparsity in sparsity_grid:\n",
    "        d = {\n",
    "            'nonzero_rows': [round(signal_nrow * sparsity)],\n",
    "            'num_measurements': [round(x) for x in update_undersampling_int_grid_coarse_pred_modified(signal_nrow, signal_ncol, sparsity, 0.15)],\n",
    "            'signal_nrow': [round(signal_nrow)],\n",
    "            'signal_ncol': [round(signal_ncol)],\n",
    "            'mc': list(range(1)),\n",
    "            'max_iter': [500],\n",
    "            'err_tol': [1e-5],\n",
    "            'sparsity_tol': [1e-4],\n",
    "            'err_explosion_tol': [100],\n",
    "            'selected_rows_frac': [1.0]\n",
    "            # 'selected_rows_frac': [round(min(1.0, 150/signal_nrow), 2)]\n",
    "            }\n",
    "        mr.append(d)\n",
    "        total_params = total_params + len(d['num_measurements'])*len(d['mc'])\n",
    "  print(total_params)\n",
    "  return exp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ut0DvLcL9Dls",
    "outputId": "48bfb67a-a5a4-4cff-d7de-1cb66d4f7df9"
   },
   "source": [
    "# real experiment json creation\n",
    "def dict_experiment_json(PT_df):\n",
    "  exp = dict_experiment(PT_df)\n",
    "  with open('just_test.json', 'w') as json_file:\n",
    "      json.dump(exp, json_file, indent = 4)\n",
    "\n",
    "dict_experiment_json(1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDptQeA9475L"
   },
   "source": [
    "# Bayes AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6t17jLS82-xr"
   },
   "source": [
    "%load_ext rpy2.ipython"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcYfKBb-vfVE"
   },
   "source": [
    "%%R\n",
    "normal_bayes_denoiser = function(y, epsilon, sigma_sd, B, mean_vec, signal_cov){\n",
    "    num = epsilon * dmvnorm(y, mean = mean_vec/sigma_sd, sigma = (diag(B) + signal_cov/sigma_sd^2))\n",
    "    deno = num + (1-epsilon)*dmvnorm(y, mean = rep(0, B), sigma = diag(B))\n",
    "    conditional_prob_nonzero = num/deno\n",
    "    return(conditional_prob_nonzero*(mean_vec/sigma_sd + (signal_cov/sigma_sd^2) %*% solve(signal_cov/sigma_sd^2 + diag(B)) %*% (y - mean_vec/sigma_sd)))\n",
    "}\n",
    "\n",
    "normal_bayes_risk = function(sigma_sd, epsilon, B, mean_vec, signal_cov){\n",
    "    num_mc = 5000\n",
    "    noise = matrix(rnorm(num_mc * B), nrow = num_mc, ncol = B)\n",
    "    signal = rmvnorm(num_mc, mean = mean_vec/sigma_sd, sigma = signal_cov/sigma_sd^2)\n",
    "    denoiser_zero = t(apply(noise, 1, normal_bayes_denoiser, epsilon, sigma_sd, B, mean_vec, signal_cov))\n",
    "    avg_risk_zero = mean(denoiser_zero^2)\n",
    "    denoiser_nonzero = t(apply(noise + signal, 1, normal_bayes_denoiser, epsilon, sigma_sd, B, mean_vec, signal_cov))\n",
    "    avg_risk_nonzero = mean((denoiser_nonzero - signal)^2)\n",
    "    return((1-epsilon)*avg_risk_zero + epsilon*avg_risk_nonzero)\n",
    "}\n",
    "\n",
    "max_normal_bayes_risk = function(epsilon, B, mean_vec, signal_cov){\n",
    "    return(optimize(normal_bayes_risk, c(0, 1e+5), epsilon, B, mean_vec, signal_cov, maximum = TRUE)$objective)\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIl60HOLLwxZ",
    "outputId": "bf37fa58-cabc-40f2-b742-059e22202a53"
   },
   "source": [
    "%%R\n",
    "max_normal_bayes_risk(0.2, 5, rep(0, 5), diag(5))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-MF2hEkll9J",
    "outputId": "2572c039-20db-414c-89ce-b79027c472b1"
   },
   "source": [
    "%%R\n",
    "dat = read.csv(\"normal_bayes_PT.csv\")\n",
    "dat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Q2vE79rQRl8"
   },
   "source": [
    "%%R\n",
    "res_normal_bayes$pred_bayes_PT = dat$bayes_PT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTys3LadnDl3",
    "outputId": "a4c93fe2-df0f-4ade-f02d-c37fc79d1b37"
   },
   "source": [
    "%%R\n",
    "res_normal_bayes$pred_bayes_PT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "Q5p6PyMknmC2",
    "outputId": "db96badd-3de5-4552-879e-29d91a7d67d9"
   },
   "source": [
    "%%R\n",
    "# james stein plot\n",
    "B = 5\n",
    "g2 <- ggplot(res_normal_js, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"AMP phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, JS\"))+\n",
    "    geom_line(aes(x = sparsity, y = pred_JS_PT, color = \"JS prediction from scalar SE\")) +\n",
    "    geom_line(aes(x = sparsity, y = pred_blocksoft_PT, color = \"blocksoft prediction from scalar SE\")) +\n",
    "    geom_line(data = res_normal_js, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, JS\")) +\n",
    "    # geom_line(aes(x = sparsity, y = pred_JS_upper_bound, color = \"JS upper bound\")) +\n",
    "    # geom_line(aes(x = sparsity, y = pred_JS_approx_1st, color = \"JS approximate (1st order)\")) +\n",
    "    # geom_line(aes(x = sparsity, y = pred_JS_approx_2nd, color = \"JS approximate (2nd order)\")) +\n",
    "    # geom_line(data = res_poisson_bs, aes(x = sparsity, y = empirical_delta_PT, color = \"poisson, N = 400, blocksoft\"))+\n",
    "    # geom_line(data = res_normal_bs, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, blocksoft\"))+\n",
    "    geom_line(data = res_normal_bayes, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, bayes\"))+\n",
    "    geom_line(data = res_normal_bayes, aes(x = sparsity, y = pred_bayes_PT, color = \"bayes prediction from scalar SE\"))+\n",
    "    geom_line(data = res_normal_bayes, aes(x = sparsity, y = sparsity, color = \"diagonal\"))+\n",
    "    geom_line(data = res_normal_bayes_small, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 1024, bayes\"))+\n",
    "    scale_color_discrete(name = \"signal distribution\")\n",
    "\n",
    "g2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "obl8--mEUj4g",
    "outputId": "996f3f08-4fb2-4f80-dca3-c636750e06e9"
   },
   "source": [
    "%%R\n",
    "# james stein plot\n",
    "B = 5\n",
    "g2 <- ggplot(res_normal_bayes, aes(x = sparsity, y = delta)) +\n",
    "    labs(title = paste(\"AMP phase transition curves with \", B, \"columns\")) +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    geom_line(data = res_normal_bayes, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 400, bayes\"))+\n",
    "    geom_line(data = res_normal_bayes, aes(x = sparsity, y = pred_bayes_PT, color = \"bayes prediction from scalar SE\"))+\n",
    "    geom_line(data = res_normal_bayes_small, aes(x = sparsity, y = empirical_delta_PT, color = \"normal, N = 1024, bayes\"))+\n",
    "    geom_line(data = res_normal_bayes_small, aes(x = sparsity, y = sparsity, color = \"diagonal\"))+\n",
    "    scale_color_discrete(name = \"signal distribution\")\n",
    "\n",
    "g2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiP-aEgvOV27"
   },
   "source": [
    "# python code to compute minimax PT\n",
    "import numpy as np\n",
    "import autograd.numpy as anp\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import time\n",
    "\n",
    "\n",
    "def multivariate_normal_pdf(y: np.ndarray, mean: np.ndarray, cov: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Returns the multivariate normal pdf at y, provided some checks are satisfied.\n",
    "    If condition number is large, returns 0.\n",
    "    If condition number is ok but somehow the quadratic form in gaussian exponent is positive, returns 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Array at which normal pdf is to be calculated.\n",
    "    mean : np.ndarray\n",
    "        Mean of normal distribution.\n",
    "    cov : np.ndarray\n",
    "        Covariance of normal distribution.\n",
    "    cov_condition : float\n",
    "        Condition number of covariance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        DESCRIPTION.\n",
    "\n",
    "    \"\"\"\n",
    "    # cov_eigvals = np.linalg.eigh(cov)[0]\n",
    "    # cov_eigvals_sorted = np.sort(np.abs(cov_eigvals))\n",
    "    # cov_condition = cov_eigvals_sorted[-1]/cov_eigvals_sorted[0]\n",
    "    if anp.linalg.det(cov) <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        exponent = -anp.matmul(y - mean, anp.matmul(anp.linalg.inv(cov), y - mean))/2\n",
    "        if exponent > 0 or anp.sqrt(anp.linalg.det(2*anp.pi*cov)) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return anp.exp(exponent)/anp.sqrt(anp.linalg.det(2*anp.pi*cov))\n",
    "\n",
    "\n",
    "def normal_bayes_vec(y: np.ndarray,\n",
    "                     signal_mean_vec: np.ndarray,\n",
    "                     signal_cov: np.ndarray,\n",
    "                     noise_cov: np.ndarray,\n",
    "                     sparsity: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs bayes denoising given noisy y = X + Z where X and Z are gaussian vectors with noise_cov non-singular.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        noisy signal.\n",
    "    signal_mean_vec : np.ndarray\n",
    "        mean of signal X.\n",
    "    signal_cov : np.ndarray\n",
    "        cov of signal X.\n",
    "    noise_cov : np.ndarray\n",
    "        cov of noise Z.\n",
    "    sparsity : float\n",
    "        X is assumed to be gaussian w.p. sparsity, and else entirely zero.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns E(X | X + Z = y).\n",
    "\n",
    "    \"\"\"\n",
    "    nonzero_bayes = signal_mean_vec + anp.matmul(signal_cov, anp.matmul(anp.linalg.inv(signal_cov + noise_cov), y - signal_mean_vec))\n",
    "    num = sparsity*multivariate_normal_pdf(y, mean = signal_mean_vec, cov = signal_cov + noise_cov)\n",
    "    deno = num + (1-sparsity)*multivariate_normal_pdf(y, mean = anp.zeros_like(signal_mean_vec), cov = noise_cov)\n",
    "    if deno > 0:\n",
    "        conditional_nonzero_prob = num/deno\n",
    "        return conditional_nonzero_prob * nonzero_bayes\n",
    "    else:\n",
    "        return nonzero_bayes\n",
    "\n",
    "\n",
    "def normal_bayes(X: np.ndarray,\n",
    "                 signal_mean_vec: np.ndarray,\n",
    "                 signal_cov: np.ndarray,\n",
    "                 noise_cov: np.ndarray,\n",
    "                 sparsity: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies bayes denoiser to each row of signal matrix when noise_cov is non-singular.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Noisy signal along whose rows denoiser is to be applied.\n",
    "    signal_mean_vec : np.ndarray\n",
    "        mean of signal rows.\n",
    "    signal_cov : np.ndarray\n",
    "        cov of signal rows.\n",
    "    noise_cov : np.ndarray\n",
    "        cov of noise. Needs to be nonsingular.\n",
    "    sparsity : float\n",
    "        sparsity level.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Each row of X denoised by Bayes denoiser.\n",
    "\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(normal_bayes_vec, 1, X, signal_mean_vec = signal_mean_vec, signal_cov = signal_cov, noise_cov = noise_cov, sparsity = sparsity)\n",
    "\n",
    "\n",
    "def normal_bayes_risk_zero(signal_mean_vec: np.ndarray,\n",
    "                           signal_cov: np.ndarray,\n",
    "                           noise_var: np.ndarray,\n",
    "                           sparsity: float) -> float:\n",
    "    B = len(signal_mean_vec)\n",
    "    rv = multivariate_normal(mean = np.zeros_like(signal_mean_vec, dtype = float), cov = noise_var*np.eye(B), allow_singular=True)\n",
    "    noise = rv.rvs(10000)\n",
    "    denoised = normal_bayes(noise, signal_mean_vec, signal_cov, noise_var*np.eye(B), sparsity)\n",
    "    return np.trace(np.matmul(denoised.T, denoised)/denoised.shape[0])/denoised.shape[1]\n",
    "\n",
    "\n",
    "def normal_bayes_risk_nonzero(signal_mean_vec: np.ndarray,\n",
    "                               signal_cov: np.ndarray,\n",
    "                               noise_var: float,\n",
    "                               sparsity: float) -> float:\n",
    "    B = len(signal_mean_vec)\n",
    "    rv_noise = multivariate_normal(mean = np.zeros_like(signal_mean_vec), cov = noise_var*np.eye(B), allow_singular = True)\n",
    "    noise = rv_noise.rvs(10000)\n",
    "    rv_signal = multivariate_normal(mean = signal_mean_vec, cov = signal_cov, allow_singular = True)\n",
    "    signal = rv_signal.rvs(10000)\n",
    "    denoised = normal_bayes(signal + noise, signal_mean_vec, signal_cov, noise_var*np.eye(B), sparsity)\n",
    "    resid = denoised - signal\n",
    "    return np.trace(np.matmul(resid.T, resid)/resid.shape[0])/resid.shape[1]\n",
    "\n",
    "\n",
    "def normal_bayes_risk(signal_mean_vec: np.ndarray,\n",
    "                    signal_cov: np.ndarray,\n",
    "                    noise_var: float,\n",
    "                    sparsity: float) -> float:\n",
    "    return (sparsity*normal_bayes_risk_nonzero(signal_mean_vec, signal_cov, noise_var, sparsity)) + ((1-sparsity)*normal_bayes_risk_zero(signal_mean_vec, signal_cov, noise_var, sparsity))\n",
    "\n",
    "\n",
    "def state_evolution(signal_mean_vec: np.ndarray,\n",
    "                    signal_cov: np.ndarray,\n",
    "                    noise_var: float,\n",
    "                    sparsity: float,\n",
    "                    delta: float) -> np.ndarray:\n",
    "    return normal_bayes_risk(signal_mean_vec,\n",
    "                             signal_cov,\n",
    "                             noise_var/delta,\n",
    "                             sparsity)\n",
    "\n",
    "\n",
    "def state_evolution_trajectory(signal_mean_vec: np.ndarray,\n",
    "                                signal_cov: np.ndarray,\n",
    "                                sparsity: float,\n",
    "                                delta: float,\n",
    "                                max_iter: int):\n",
    "    B = len(signal_mean_vec)\n",
    "    iter = 0\n",
    "    noise_var = sparsity*np.trace(signal_cov + np.matmul(signal_mean_vec.reshape((B, 1)), signal_mean_vec.reshape((1, B))))/(B*delta)\n",
    "    # noise_var = 1e-5\n",
    "    noise_var_list = [noise_var]\n",
    "    # print(\"iteration \"+str(iter)+\":\"+str(noise_var))\n",
    "    while iter<max_iter:\n",
    "        iter = iter+1\n",
    "        noise_var = state_evolution(signal_mean_vec,\n",
    "                                    signal_cov,\n",
    "                                    noise_var,\n",
    "                                    sparsity,\n",
    "                                    delta)\n",
    "        noise_var_list = noise_var_list + [noise_var]\n",
    "        print(\"iteration \"+str(iter)+\":\"+str(noise_var))\n",
    "    return noise_var_list\n",
    "\n",
    "\n",
    "def max_normal_bayes_risk(signal_mean_vec: np.ndarray,\n",
    "                          signal_cov: np.ndarray,\n",
    "                          sparsity: float):\n",
    "    def f(noise_var, signal_mean_vec, signal_cov, sparsity):\n",
    "        return 1-(normal_bayes_risk(signal_mean_vec, signal_cov, noise_var, sparsity)/noise_var)\n",
    "    start_time = time.time()\n",
    "    res = scipy.optimize.minimize_scalar(f, bounds=(1e-3, 10), args = (signal_mean_vec, signal_cov, sparsity), method = 'bounded').fun\n",
    "    end_time = time.time()\n",
    "    return 1-res\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79u4zbNuznGg"
   },
   "source": [
    "PT_df = pd.read_csv('normal_bayes_PT.csv')\n",
    "PT_df['sparsity'] = [round(x, 2) for x in PT_df['sparsity']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8GwsQSD1blA",
    "outputId": "ae5dba91-4640-4f5d-ec68-a0c4ce960331"
   },
   "source": [
    "np.array(PT_df['sparsity'] == 0.05)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ojons6Rvzu-Q",
    "outputId": "68d48a34-2864-4690-84fa-6932ea8c394b"
   },
   "source": [
    "# coarser sparsity grid: undersampling based on dataframe\n",
    "def update_undersampling_int_grid_coarse_bayes_PT(signal_nrow, signal_ncol, sparsity, band_half_width, mean_vec, signal_cov, PT_df):\n",
    "  # PT = max_normal_bayes_risk(mean_vec, signal_cov, sparsity)\n",
    "  dat_small = PT_df[PT_df['sparsity'] == sparsity]\n",
    "  PT = dat_small['bayes_PT'].item()\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, PT - band_half_width)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, PT + band_half_width)))\n",
    "  range_list = range(undersampling_int_lower, undersampling_int_upper + 1)\n",
    "  return [min(range_list), np.percentile(range_list, 25), np.median(range_list), np.percentile(range_list, 75), max(range_list)]\n",
    "  # return list(range_list)\n",
    "\n",
    "update_undersampling_int_grid_coarse_bayes_PT(1600, 5, 0.5, 0.01, np.zeros(5), np.eye(5), PT_df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIonTEHDIcka"
   },
   "source": [
    "# coarser sparsity grid: undersampling based on predicted\n",
    "def update_undersampling_int_grid_coarse_bayes(signal_nrow, signal_ncol, sparsity, band_half_width, mean_vec, signal_cov):\n",
    "  PT = max_normal_bayes_risk(mean_vec, signal_cov, sparsity)\n",
    "  undersampling_int_lower = max(1, int(signal_nrow * max(0, PT - band_half_width)))\n",
    "  undersampling_int_upper = min(signal_nrow - 1, int(signal_nrow * min(1, PT + band_half_width)))\n",
    "  return list(range(undersampling_int_lower, undersampling_int_upper + 1))\n",
    "\n",
    "update_undersampling_int_grid_coarse_bayes(400, 5, 0.3, 0.05, np.zeros(5), np.eye(5))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8LhMUrQ_pu0",
    "outputId": "bee64a17-b73c-48bf-c219-b33bcf749da3"
   },
   "source": [
    "%%R\n",
    "optimize(normal_bayes_risk, c(0, 1e+10), epsilon = 0.2, B = 10, mean_vec = rep(0, 10), signal_cov = diag(10), maximum = TRUE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50VPw6AvVtmd"
   },
   "source": [
    "# bayes amp experiment dicts\n",
    "def dict_experiment(PT_df) -> dict:\n",
    "  total_params = 0\n",
    "  exp = dict(table_name='AMP_matrix_recovery_normal_bayes_approx_jacobian',\n",
    "             base_index=0,\n",
    "             description='Performs Bayes denoising with complete knowledge of sparsity and signal characteristics. Nonzeros of signal iid N(0,1). Sparsity varies from 0.05 to 0.95 in increment of 0.05. Signal rows vary in [1600, 3200] and 5 columns. Undersampling integer grid half-width 0.05 around the predicted PT value which is max Bayes risk. Only min, quartiles and max of the interval are taken. 25 MC runs per param point. Jacobian approximated by selecting only 150 signal rows randomly.',\n",
    "             db_url='sqlite:///data/EMS.db3',\n",
    "             multi_res=[])\n",
    "  mr = exp['multi_res']\n",
    "  signal_nrow_grid = [1600, 3200]\n",
    "  signal_ncol_grid = [5]\n",
    "  sparsity_grid = [round(x, 2) for x in np.linspace(0.05, 0.95, num = 19)]\n",
    "  for signal_nrow in signal_nrow_grid:\n",
    "    for signal_ncol in signal_ncol_grid:\n",
    "      for sparsity in sparsity_grid:\n",
    "        d = {\n",
    "            'nonzero_rows': [round(signal_nrow * sparsity)],\n",
    "            'num_measurements': [round(x) for x in update_undersampling_int_grid_coarse_bayes_PT(signal_nrow, signal_ncol, sparsity, 0.1, np.zeros(signal_ncol), np.eye(signal_ncol), PT_df)],\n",
    "            'signal_nrow': [round(signal_nrow)],\n",
    "            'signal_ncol': [round(signal_ncol)],\n",
    "            'mc': list(range(25)),\n",
    "            'max_iter': [500],\n",
    "            'err_tol': [1e-5],\n",
    "            'sparsity_tol': [1e-4],\n",
    "            'err_explosion_tol': [100],\n",
    "            'selected_rows_frac': [round(150/signal_nrow, 2)]\n",
    "            }\n",
    "        mr.append(d)\n",
    "        total_params = total_params + len(d['num_measurements'])*len(d['mc'])*len(d['selected_rows_frac'])\n",
    "  print(total_params)\n",
    "  return exp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztyitFwSWdlm",
    "outputId": "236b31e1-861e-4a33-e000-3dfc09c4ae8f"
   },
   "source": [
    "# real experiment json creation\n",
    "def dict_experiment_json(PT_df):\n",
    "  exp = dict_experiment(PT_df)\n",
    "  with open('AMP_matrix_recovery_normal_bayes_approx_jacobian_2.json', 'w') as json_file:\n",
    "      json.dump(exp, json_file, indent = 4)\n",
    "\n",
    "dict_experiment_json(PT_df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL5foRHe_apH"
   },
   "source": [
    "# Scaling laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hI93KgDi_Zlt"
   },
   "source": [
    "%%R\n",
    "res_normal_bayes_1024 = dplyr::filter(res_normal_bayes, signal_nrow == 1024)\n",
    "offset = res_normal_bayes_1024$empirical_delta_PT\n",
    "res_normal_bayes_else = dplyr::filter(res_normal_bayes, signal_nrow != 1024)\n",
    "# res_normal_bayes_else = dplyr::filter(res_normal_bayes_else, signal_nrow != 100)\n",
    "# res_normal_bayes_else$diff = res_normal_bayes_else$empirical_delta_PT - rep(offset, 5)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dVgQGOIDikz",
    "outputId": "b7ea43a8-0890-42d3-fd4b-77d06376bd23"
   },
   "source": [
    "%%R\n",
    "alpha_grid = seq(0.01, 1, by = 0.01)\n",
    "R_grid = rep(0, length(alpha_grid))\n",
    "res_normal_bayes_else$signal_nrow = as.numeric(res_normal_bayes_else$signal_nrow)\n",
    "for(i in 1:length(alpha_grid)){\n",
    "    R_grid[i] = summary(lm(diff ~ I(signal_nrow^(-alpha_grid[i]))-1, data = res_normal_bayes_else))$r.squared\n",
    "}\n",
    "i = which.max(R_grid)\n",
    "summary(lm(diff ~ I(signal_nrow^(-alpha_grid[i])) - 1, data = res_normal_bayes_else))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXiVA0bYGv7K",
    "outputId": "d986c564-b219-475a-98af-9837fa431e71"
   },
   "source": [
    "%%R\n",
    "alpha_grid = seq(0.01, 3, by = 0.01)\n",
    "R_grid = rep(0, length(alpha_grid))\n",
    "res_normal_bayes_else$signal_nrow = as.numeric(res_normal_bayes_else$signal_nrow)\n",
    "for(i in 1:length(alpha_grid)){\n",
    "    R_grid[i] = summary(lm(empirical_delta_PT ~ as.factor(sparsity) + I(signal_nrow^(-alpha_grid[i]))-1, data = res_normal_bayes_else))$r.squared\n",
    "}\n",
    "i = which.max(R_grid)\n",
    "summary(lm(empirical_delta_PT ~ as.factor(sparsity) + I(signal_nrow^(-alpha_grid[i])) - 1, data = res_normal_bayes_else))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMXZQN2AYOQL",
    "outputId": "74a1f012-3966-419e-811f-7b3bf4fbd4c5"
   },
   "source": [
    "%%R\n",
    "alpha_grid[which.max(R_grid)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "HcLApEYPjRT2",
    "outputId": "484eb41e-6420-4a35-c866-e13513ffc263"
   },
   "source": [
    "%%R\n",
    "plot(alpha_grid, R_grid)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E687R2ezjabs",
    "outputId": "5ae49a9a-01aa-4092-fea1-ec8be62ab7f1"
   },
   "source": [
    "%%R\n",
    "dat = read.csv(\"normal_bayes_PT.csv\")\n",
    "dat"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "authorship_tag": "ABX9TyMP8B7zIfPUIKlagVbG802g",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
